import random
import typing
import collections

import pandas as pd
import psqlparse
import streamlit as st
import st_aggrid

import src.config as config
from src.encoding import TreeBuilder, SQLEncoder, RangeVar, WhereCondition
from src.hints import HyperQO
from src.mcts import MCTSHinterSearch
from src.net import TreeNet
from src.tree_lstm import SPINN


def get_hyper_qo_instance():
    random.seed(113)

    tree_builder = TreeBuilder()

    value_network = SPINN(head_num=config.NET_HEAD_NUM,
                          input_size=7 + 2,
                          hidden_size=config.NET_HIDDEN_SIZE,
                          table_num=50,
                          sql_size=40 * 40 + config.MAX_COLUMN_ID).to(config.DEVICE_NAME)

    tree_net = TreeNet(tree_builder=tree_builder, value_network=value_network)
    mcts_searcher = MCTSHinterSearch()

    hint_generator = HyperQO(tree_net=tree_net,
                             sql2vec=SQLEncoder(),
                             value_extractor=tree_builder.value_extractor,
                             mcts_searcher=mcts_searcher)
    return hint_generator


DEFAULT_HINT_GENERATOR = get_hyper_qo_instance()


class DotFileGenerator:
    def __init__(self, graph_name: typing.Optional[str] = None):
        self.__nodes = dict()
        self.__edges = collections.defaultdict(set)
        self.__graph_name = "TestGraph" if graph_name is None else graph_name

    def add_node(self, v_name: str, v_data: typing.Optional[str] = None):
        if v_data is None:
            self.__nodes[v_name] = v_name
        else:
            self.__nodes[v_name] = v_data

    def add_edge(self, v1_name: str, v2_name: str):
        self.__edges[v1_name].add(v2_name)

    def to_graphviz_file(self):
        res = f"digraph {self.__graph_name}{{\n"
        for v_name, v_data in self.__nodes.items():
            if "Scan" in v_data:
                res += f"\t{v_name}[label=\"{v_data}\"][shape=box][color=red][width=3];\n"
            elif "Join" in v_data or 'Nested Loop' in v_data:
                res += f"\t{v_name}[label=\"{v_data}\"][shape=box][color=blue][width=3];\n"
            else:
                res += f"\t{v_name}[label=\"{v_data}\"][shape=box][width=3];\n"
        for v1_name, v2_names in self.__edges.items():
            for v2_name in v2_names:
                res += f"\t{v1_name} -> {v2_name}\n"
        res += "}"
        return res


def get_plan_tree(plan_ob: dict):
    assert "Plan" in plan_ob, "Key Error: Plan"
    dot_file_generator = DotFileGenerator()
    undefined_mark = "undefined"

    def __get_name(level: int, node_type: str):
        return f"""{node_type.replace(' ', '')}{level}"""

    def __inner_dfs(node: dict, level=0):
        node_type = node["Node Type"]
        startup_cost = node.get("Startup Cost", undefined_mark)
        total_cost = node.get("Total Cost", undefined_mark)
        plan_rows = node.get("Plan Rows", undefined_mark)

        dot_file_generator.add_node(
            f"""{__get_name(level, node_type)}""",
            f"""{node_type}\\nstart: {startup_cost}, tol: {total_cost}\\n row: {plan_rows}"""
        )

        for child in node.get("Plans", []):
            __inner_dfs(child, level + 1)
            dot_file_generator.add_edge(f"""{__get_name(level, node_type)}""",
                                        f"""{__get_name(level + 1, child['Node Type'])}""")

    __inner_dfs(plan_ob["Plan"])
    return dot_file_generator


def get_query_plan_detail(plan):
    return {
        'detail': plan,
        'tree': get_plan_tree(plan).to_graphviz_file()
    }


def get_all_query_plans(sql):
    (pg_plan_time, pg_latency,
     mcts_time, hinter_plan_time, mhpe_time, hinter_latency,
     actual_plans, actual_time,
     chosen_leading_pairs) = DEFAULT_HINT_GENERATOR.optimize(sql)

    plan_time_record = {
        'MCTSæ¶ˆè€—(s)': mcts_time,
        'MHPEè¯„ä¼°æ¶ˆè€—(s)': mhpe_time,
        'è®¡åˆ’ç”Ÿæˆæ¶ˆè€—(s)': hinter_plan_time,
        'è®¡åˆ’æ‰§è¡Œæ¶ˆè€—(s)': hinter_latency,
        'é€‰ä¸­çš„æŸ¥è¯¢è®¡åˆ’': actual_plans[0],
        'é€‰ä¸­çš„æŸ¥è¯¢è®¡åˆ’æ‰§è¡Œæ—¶é—´(s)': actual_time[0],
        'PGè®¡åˆ’æ—¶é—´': pg_plan_time,
        'PGè®¡åˆ’æ‰§è¡Œæ—¶é—´': pg_latency
    }
    query_plans_table = list()
    details = list()
    for i, ((mean_t, v_t, v2_t), leading, leading_utility, plan_json) in enumerate(chosen_leading_pairs):
        query_plans_table.append([i + 1, leading, mean_t, leading_utility])
        details.append(get_query_plan_detail(plan_json))
    return query_plans_table, details, plan_time_record


def print_all_query_plans(res: list[list[typing.Any]], headers: list[str]):
    df = pd.DataFrame(res, columns=headers)
    # # ä¸æ˜¾ç¤ºç´¢å¼•åˆ—
    options_builder = st_aggrid.GridOptionsBuilder.from_dataframe(df, index=False)
    options_builder.configure_default_column(min_column_width=10,
                                             groupable=True, value=True, enableRowGroup=True,
                                             editable=False, wrapText=True)

    options_builder.configure_column("id", width=70)
    options_builder.configure_column("æŸ¥è¯¢è®¡åˆ’", width=250)
    options_builder.configure_column("å½“å‰ä¸ç¡®å®šæ€§åº¦é‡", width=150)
    options_builder.configure_column("leadingå¯ç”¨åº¦", width=150)

    grid_options = options_builder.build()
    st_aggrid.AgGrid(df, grid_options, theme='balham')
    return df


def get_sql_info(sql: str):
    sql_parse_result = psqlparse.parse_dict(sql)[0]["SelectStmt"]
    # # NOTE: BING 2023/5/18 ä¸‹åˆ9:55 è·å¾—FROMå­å¥ä¸­çš„è¡¨å, ä¿å­˜åœ¨table_listä¸­
    # # ... æµ‹è¯•ç”¨ä¾‹ä¸­çš„è¡¨æ•°ç›®å¿…é¡»å¤§äºç­‰äº2
    table_list = [str(RangeVar(x["RangeVar"])) for x in sql_parse_result["fromClause"]]

    # # NOTE: BING 2023/5/18 ä¸‹åˆ10:02 è·å¾—WHEREå­å¥ä¸­çš„è°“è¯, ä¿å­˜åœ¨comparison_listä¸­
    comparison_list = [str(WhereCondition(x)) for x in sql_parse_result["whereClause"]["BoolExpr"]["args"]]

    # # è·å–SQLè¯­
    return {
        'æ¶‰åŠåˆ°çš„è¡¨': table_list,
        'æ¶‰åŠåˆ°çš„è°“è¯': comparison_list
    }


def main_ui():
    st.set_page_config(page_title="æŸ¥è¯¢ä¼˜åŒ–-å±•ç¤ºç•Œé¢", page_icon="ğŸ“Š")
    st.title('æŸ¥è¯¢ä¼˜åŒ–å±•ç¤ºç•Œé¢')
    st.markdown('å½“å‰è´Ÿè½½: JOB-Static')
    # # åˆ†å‰²çº¿
    st.markdown('---')
    st.markdown('''
        æœ¬é¡¹ç›®æ—¨åœ¨åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯, å¯¹åŸç”Ÿçš„åŸºäºè§„åˆ™çš„æŸ¥è¯¢ä¼˜åŒ–å™¨è¿›è¡Œå¢å¼º, æé«˜æŸ¥è¯¢ä¼˜åŒ–å™¨çš„æ€§èƒ½ã€‚
        > æœ¬é¡¹ç›®éœ€é…åˆPostgreSQLæ•°æ®åº“ä½¿ç”¨, æœ¬ç•Œé¢ä»…ç”¨äºå±•ç¤ºæŸ¥è¯¢ä¼˜åŒ–å™¨çš„æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆæƒ…å†µ, åœ¨å®é™…ä¸­åº”ç”¨æ—¶, éœ€è¦ä¿®æ”¹ç›¸å…³å˜é‡
        
        æœ¬é¡¹ç›®ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†:
        - SQLè¯­å¥çš„è§£æå’Œç¼–ç 
        - Hintçš„ç”Ÿæˆ
        - ä¸åŒæŸ¥è¯¢è®¡åˆ’çš„ç¼–ç 
        - ä»£ä»·é¢„æµ‹æ¨¡å‹çš„è®­ç»ƒ
        - ä»£ä»·é¢„æµ‹æ¨¡å‹çš„åº”ç”¨
        
        è¯·åœ¨ä¸‹æ–¹è¾“å…¥SQLè¯­å¥ï¼Œç‚¹å‡»æ‰§è¡ŒæŒ‰é’®ï¼Œå³å¯æŸ¥çœ‹æŸ¥è¯¢è®¡åˆ’çš„ç”Ÿæˆæƒ…å†µã€‚
    ''')
    # # åˆ›å»ºä¸€ä¸ªè¾“å…¥æ¡†, æ”¯æŒè¾“å…¥SQLè¯­å¥
    sql = st.text_input('SQLè¯­å¥', placeholder='eg: select min(id), ... from movie,... where id>1000')
    sql = sql.replace("\n", " ")
    # # åˆ›å»ºä¸€ä¸ªæŒ‰é’®, è·å–SQLè¯­å¥, SQLè¯­å¥æ‰§è¡Œ, è·å–ç»“æœï¼Œä»¥åˆ—è¡¨å½¢å¼å‘ˆç°
    if st.button('æ‰§è¡Œ'):
        # # æ˜¾ç¤ºloading, ç”¨äºæç¤ºç”¨æˆ·æ­£åœ¨æ‰§è¡Œ
        # # æ¸…é™¤ä¸Šä¸€æ¬¡çš„ç»“æœ
        st.text('')
        with st.spinner('æ­£åœ¨æ‰§è¡Œä¸­...'):
            # # æ‰§è¡Œ
            res, details, plan_time_record = get_all_query_plans(sql)
        # # æ‰§è¡Œå®Œæ¯•, éšè—loading
        st.success('æ‰§è¡Œå®Œæ¯•!')

        # # å±•ç¤ºJSONæ•°æ®çš„è§£æç»“æœ
        sql_info_col, plan_time_col = st.columns(2)

        sql_info_col.json({
            'SQL': {'statement': sql},
            'è§£æç»“æœ': get_sql_info(sql)
        }, expanded=False)

        plan_time_col.json(plan_time_record, expanded=False)
        headers = [
            'id',
            'æŸ¥è¯¢è®¡åˆ’',
            'å½“å‰ä¸ç¡®å®šæ€§åº¦é‡',
            'leadingå¯ç”¨åº¦',
        ]
        df = print_all_query_plans(res, headers)
        df_zipped = list(zip(df['id'], df['æŸ¥è¯¢è®¡åˆ’']))
        # for idx, btn in enumerate(st.columns(4)):
        #     # # è®¾ç½®åœ†è§’
        #     btn.markdown(
        #         f'<button id="click-to-fetch{idx}" '
        #         f'style="border-radius: 5px; background-color: #cccccc; color: #fffff; width: 90px">'
        #         f'<a href="#{df_zipped[idx][1]}">12</a></button>',
        #         unsafe_allow_html=True)

        for idx in range(len(df_zipped)):
            st.markdown('---')
            st.markdown(f'<h3 id="{df_zipped[idx][1]}">æç¤ºè¯­ {df_zipped[idx][1]} ç”Ÿæˆçš„æŸ¥è¯¢è®¡åˆ’çš„è¯¦ç»†ä¿¡æ¯</h3>',
                        unsafe_allow_html=True)
            # detail_col, tree_col = st.columns(2)
            st.markdown('**æŸ¥è¯¢è®¡åˆ’è¯¦æƒ…**')
            st.json(details[idx]['detail'], expanded=False)
            st.markdown('**æŸ¥è¯¢è®¡åˆ’æ ‘**')
            st.graphviz_chart(details[idx]['tree'])


if __name__ == '__main__':
    main_ui()
